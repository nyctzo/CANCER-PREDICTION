# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11rksjZ6cEF6KQBJVHUzKT3LzwyfSYmFo

importing the dependencies
"""

import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

"""device configuration"""

# check for cuda availability
device = torch.device("cuda" if torch.cuda.is_available() else "cpu" )
print(f"using device: {device}")

"""load the breast cancer datasets"""

# load the breast cancer datasets
data = load_breast_cancer()
X = data.data
Y = data.target

#split the datasets into training sets and test sets
X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.2, random_state= 42)

print(X.shape)
print(X.train.shape)
print(X.test.shape)

"""standardize the data using standard scalar"""

# standardize the data using standard scalar
scaler = Standardscaler()
x_train = scaler.fit_transform(X_train)
x_test = scaler.transform(X_test)

type(X_train)

#convert data into pytorch sensors and move it to gpu

X_train = torch.tensor(X_train, dtype = torch.float32 ).to(device)
Y_train = torch.tensor(Y_train, dtype = torch.float32 ).to(device)
X_test = torch.tensor(X_test, dtype = torch.float32 ).to(device)
Y_test = torch.tensor(Y_test, dtype = torch.float32 ).to(device)

"""NEURAL NETWORK ARCHITECTURE"""

#define the neural network architecture
class NeuralNet(nn.Module):
  def __init__(self, input_size, hidden_size, output_size):
    super(NeuralNet, self).__init__()
    self.fc1 = nn.Linear(input_size, hidden_size)
    self.relu = nn.ReLU()
    self.fc2 = nn.Linear(hidden_size, output_size)
    self.sigmoid = nn.Sigmoid()

  def forward(self, x):
    out = self.fc1(x)
    out = self.relu(out)
    out = self.fc2(out)
    out = self.sigmoid(out)
    return out

# define hyperparamters
input_size = X_train.shape[1]
hidden_size = 64
output_size = 1
learning_rate = 0.001
num_epochs = 100

#initialize the neural network and send it to the gpu
model = NeuralNet(input_size, hidden_size, output_size). to(device)

#define the loss and the optimizer
criterion = nn.BCELoss()
optimizer  = optim.Adam(model.parameters(), lr = learning_rate)

#training the model
for epoch in range(num_epochs):
  model.train()
  optimizer.zero_grad()
  outputs = model(X_train)
  loss = criterion(outputs, Y_train.view(1))
  loss.backward()
  optimizer.step()

#calculate accuracy
with torch.no_grad():
  predicted = outputs.round()
  correct = (predicted == Y_train.view(-1, 1)).float().sum()
  accuracy  = correct/Y_train.size(0)
  if (epoch+1) % 10 == 0:
    print(f"epoch: {epoch+1}/{num_epochs}, loss: {loss.item():.4f}, accuracy: {accuracy.item():.4f}%")

"""MODEL EVALUATION"""

#Evaulation on training set
model.eval()
with torch.no_grad():
  outputs = model(X_train)
  predicted = outputs.round()
  correct = (predicted == Y_train.view(-1, 1)).float().sum()
  accuracy = correct/Y_train.size(0)
  print(f"Accuracy on training data: {accuracy.item()*100:.2f}%")

#Evaulation on test set
model.eval()
with torch.no_grad():
  outputs = model(X_test)
  predicted = outputs.round()
  correct = (predicted == Y_test.view(-1, 1)).float().sum()
  accuracy = correct/Y_test.size(0)
  print(f"Accuracy on test data: {accuracy.item()*100:.2f}%")